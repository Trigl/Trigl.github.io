---
layout:     post
title:      "Designing Data-Intensive Applications 读书笔记（I）"
subtitle:   "构建可靠的、可扩展和可维护的应用"
date:       2018-05-30
author:     "Ink Bai"
catalog:    true
header-img: "http://ox2ru2icv.bkt.clouddn.com/image/post/ddia-1.jpg"
tags:
    - Big Data
---

> 17 年听说了这本神书 **Designing Data-Intensive Applications**，可以说这是一本全面讲解了大数据整个生态的百科全书，之前快速地看过前几章，感觉讲解地很系统而且通俗易懂，但是看到后面开始讲解更多细节性的内容慢慢地有点跟不上节奏了。作为一名数据从业人员感觉很有必要通过这本书把数据系统层面的内容整个做一个了解，所以这次在阅读的过程中会作一些笔记或者说是翻译以加深自己的记忆和理解。目标是一周更新一章，希望用两个月左右的时间读完这本书吧！

![](http://ox2ru2icv.bkt.clouddn.com/image/content/ddia-cover.png)

现在很多应用都是数据密集型应用，所谓的数据密集型应用，是指数据是其主要挑战，数据量、数据复杂度以及数据变化的速度是要考虑的主要方面。与之对应的是计算密集型，即 CPU 是主要瓶颈。

数据密集型应用实际上是由多个标准化组件组合而成的，这些组件提供相应通用性的功能，例如很多应用都需要：

- 存储及查询数据（数据库）
- 记录一个复杂操作的结果，加速读操作（缓存）
- 允许用户通过关键字查数据，并且可以用多种方式过滤数据（搜索索引）
- 将消息发送到其他程序，方便异步处理（流处理）
- 周期性处理大量的累计数据（批处理）

这些功能听起来是不是很常见，而且你可以想到相应的工具去实现，简单点讲数据系统就是将它们整合在一起，但其实并没有那么简单。因为对应到不同的应用有不同的需求，然而有很多种不同的数据库，也有多种不同的缓存方式，不同的建立搜索索引的方法等等，那么我们如何做出选择呢？所以应该是就事论事，具体情况具体分析，我们应该根据我们的需求正确选择出最适合的工具和途径。

通常我们会认为数据库、队列、缓存等是完全不同的工具，即使一个数据库和一个消息队列表面上有一些相同点（能存储数据），但其实他们解决的痛点、内部的实现和性能等都是完全不同的。那么为什么我们要把他们统一放在数据系统这面大旗底下呢？

首先，这些不同类别工具的边界正在逐渐变模糊，他们都可以服务于数据系统。例如近年来出现了很多用于存储数据和处理数据的工具，他们都被优化成可以适用于多种应用场景而不再只是单一的某个方面。例如有些数据存储也可以作为消息队列来使用（如 Redis），有些消息队列也会提供像数据库一样的持久化保证（如 Kafka）。
其次，现在的应用一般都有各种各样的需求，想要用一种工具完美满足所有需求那是不存在的。所以我们一般都会把一个应用拆分成不同的部分，对应每个部分使用专门的工具来高效处理，最后通过应用代码把这些工具整合在一起。

举个栗子，假设现在有一个通过应用管理的缓存层（使用 Memcached 或者其他类似的），或者有一个全文搜索服务器（例如 Elasticsearch 或者 Solr）与主数据库分离，那么就需要使缓存或者索引和数据库保持同步，这就是通过应用代码来实现的，下图是该例子的架构，具体细节后面的章节我们会再讲。

![](http://ox2ru2icv.bkt.clouddn.com/image/content/ddia-fig1-1.png)

当设计一个数据系统或服务的时候，会遇到很多奇怪的问题：系统内部出错了，如何确保数据的正确性和完整性？系统的某个部分退化，如何为客户提供始终如一的良好性能？负载增加的时候如何扩展？一个好的 API 应该如何实现？有很多因素会影响到数据系统的设计，包括相关人员的能力和经验，对遗留系统的一些依赖，时间成本，监管约束等。因素很大程度上取决于情况。本书我们主要关注对于大多数软件系统来讲都很重要的三点：

**可靠性**
即使出现了某些问题（软硬件错误或者偶然的人为失误），系统应该保证始终能够正常工作

**可扩展性**
随着系统的增长（数据量、流量或复杂度），应该有相应的应对措施

**可维护性**
随着时间的推移，许多不同的人将在系统上工作(工程和操作，既保持当前的行为，又使系统适应新的用例)，并且他们都应该能够有效地在系统上工作。

实际工作中大家可能忽略了这三个准则的重要性，那么下面让我们来真正理解可靠性、可扩展性和可维护性意味着什么。
## 可靠性
对软件而言，可靠性意味着：
- 应用执行用户期望的函数
- 允许用户犯错或者错误地使用该软件
- 在预期的负载和数据量下，对不同的需求都能提供良好的性能
- 系统防止任何未经授权的访问和滥用

可靠性必须保证出了问题也能正常使用，系统出了问题称为 **错误（faults）**，如果系统可以预料并且可以做出合适的应对我们称之为 **容错性（fault-tolerant）** 或者 **韧性（resilient）**。注意错误（faluts）和故障（failure）不同，错误（faluts）通常定义为系统的某个组件偏离其规范操作，然而故障（failure）是指整个系统停止向用户提供服务，错误太多可能会导致系统故障，但是想要完全没有错误又是不可能的，因此最好的方法就是设计良好的容错机制。
#### 硬件错误
当发生了系统故障的时候，首先想到的就是一些硬件错误：硬盘坏了、RAM 出现故障、电网停电、太平洋底的鲨鱼咬断了光纤等等。硬盘平均经过 10-50 年就会出故障，因此在一个有一万个硬盘的存储集群上，平均每天都会有一个硬盘挂掉。

对于硬盘故障，第一个常用的方式是增加备份。磁盘可以设置成 RAID（独立硬盘冗余阵列），服务器设置成双电源和热交换 CPU，数据中心配备电池和柴油发电机作为备用电源。当某一个组件发生故障，冗余备份可以代替它，当然在恢复的时间內系统是挂掉的，但是对大部分应用来说这点宕机时间应该并不是灾难性的，然而却可以成功避免系统完全崩溃。

随着数据量和应用的计算需求的提高，更多应用需要使用大量的机器，这就增大了硬件故障发生的几率。而且许多云平台如 AWS 的虚拟机实例经常没有任何警告就不可用了，那是因为与可靠性相比，云平台优先考虑机器的灵活性和弹性。因此现在越来越趋向于设计能够允许整个机器出现故障的应用系统，通过软件层面的容错性技术来代替硬件备份，这种系统具有操作上的优势：普通的单机系统宕机或者更新（例如需要发布一个新的安全补丁）的时候，有一段时间是不可用的，然而一个可以允许机器故障的系统某个时间只更新某个节点，不需要整个系统都停掉。
#### 软件错误
另一种类型的错误是系统内部的错误，也就是软件错误。这种错误很难被预测到，并且由于软件可能运行在多个机器节点中，所以软件错误更容易导致整个系统挂掉。例如：
- 因为不正常的输入导致应用服务器的所有机器全部挂掉的 bug
- 一个死循环耗尽了所有的共享资源如 CPU、内存、磁盘空间和网络带宽
- 系统依赖的某个服务变慢、无响应或者返回异常的结果
- 连环故障，即组件中的一个小错误可能会导致另一个组件出错，最后触发了更多的错误

导致这些软件错误的 bug 通常都潜伏很久，只有在某些非常奇怪的情况下才会被触发。对于软件错误没有什么系统快速的解决方式，只能通过各种细节来避免：仔细思考系统可能遇到的异常情况；全面的测试；模块分离；允许程序崩溃并且能够恢复重启；测量、监控和分析生产环境下系统的指标。
#### 人为错误
软件系统是人设计和构建的，也是人使用的，人也恰恰是最能犯错的，据调查操作者错误配置是服务异常的主要原因，而硬件错误仅占 10-25%。那么面对人类不可靠这个不可避免的事实，如何使我们的系统更可靠呢？可以从如下几个方面入手：
- 尽可能设计不易出错的系统。例如良好设计的抽象、API、管理接口就可以很大层度上避免错误，但是如果接口过分严格，限制了对其工作人员的很多操作，那么这个系统就会显得很难用。所以这需要很好的平衡。
- 将人最容易犯错的地方和容易导致系统故障的地方分离开，并且提供非生产环境进行充分探索和实验。
- 进行从单元测试到集成测试和手动测试的全面全方位测试。自动化测试也应当被广泛使用，它可以检测到某些正常操作覆盖不到的细枝末节。
- 能够方便快捷恢复到系统之前地样子。例如，能够快速回滚配置文件，逐步应用新代码（保证即使有问题也只影响一小撮用户），提前准备能够重新计算数据的工具（当原有数据有误时）
- 建立清晰明确的监控，例如性能指标和错误率。监控能够提前向我们发出警报，检验是否与我们预期结果相符。当出现问题时，这些监控指标对于排查问题更是意义重大。
- 对人员进行良好地管理和培训

## 可扩展性
## 可维护性
## 总结
